{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA final exam (Fall 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exam consists of 2 tasks. The two tasks are independent of each other. You can solve them in any order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Natural Language Processing (50 pts)\n",
    "This part of the exam will analyze a real-world negotiation dataset:\n",
    "\n",
    "Two participants take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. This design keeps the task tractable, while still facilitating linguistically rich and personal conversations.\n",
    "\n",
    "At the end of each negotiation, both negotiators receive an outcome score (`outcome`) reflecting their success in achieving their goals. The dataset is divided into two data frames:\n",
    "\n",
    "1. `df_negotiations`, with columns:\n",
    "    - `negotiation_id`: the negotiation identifier\n",
    "    - `agent`: the agent active in that turn, either `mt_agent_1` or `mt_agent_2` (first and second to interact)\n",
    "    - `message`: the message sent to the other agent\n",
    "    - `turn`: the negotiation turn\n",
    "2. `df_meta`, meta information for each negotiation with the outcome and agent background:\n",
    "    - `gender`: (male, female, other)\n",
    "    - `age`: integer\n",
    "    - `outcome`: integer\n",
    "\n",
    "We are interested in finding out: what makes a good (/bad) negotiator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Coding Questions (29 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>message</th>\n",
       "      <th>negotiation_id</th>\n",
       "      <th>turn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>Hello! üôÇ Let's work together on a deal for the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>Hey! I'd like some more firewood to keep my do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>I need firewood as well. We have a large group...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>I see. üòÆ What are you least interested in?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>We can make do without extra water. Can we tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agent                                            message  \\\n",
       "0  mturk_agent_1  Hello! üôÇ Let's work together on a deal for the...   \n",
       "1  mturk_agent_2  Hey! I'd like some more firewood to keep my do...   \n",
       "2  mturk_agent_1  I need firewood as well. We have a large group...   \n",
       "3  mturk_agent_2         I see. üòÆ What are you least interested in?   \n",
       "4  mturk_agent_1  We can make do without extra water. Can we tra...   \n",
       "\n",
       "   negotiation_id  turn  \n",
       "0               0     0  \n",
       "1               0     0  \n",
       "2               0     1  \n",
       "3               0     1  \n",
       "4               0     2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_negotiations = pd.read_csv('negotiations.csv')\n",
    "df_negotiations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>negotiation_id</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>797</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>65</td>\n",
       "      <td>male</td>\n",
       "      <td>909</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>34</td>\n",
       "      <td>female</td>\n",
       "      <td>909</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>135</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agent  age  gender  negotiation_id  outcome\n",
       "0  mturk_agent_1   31  female             797       21\n",
       "1  mturk_agent_2   26    male             797       15\n",
       "2  mturk_agent_1   65    male             909       18\n",
       "3  mturk_agent_2   34  female             909       23\n",
       "4  mturk_agent_1   26    male             135       26"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.read_csv('negotiations_meta.csv')\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 (2 pt)**\n",
    "/Discussion:/ We are interested in analyzing negotiation outcomes by analyzing language usage. In order to use TF-IDF to accomplish this, we will treat all turns from one negotiator in a single negotiation as a \"document\". Why would this definition of \"document\" be preferred over the following two alternatives? Give at least one argument per alternative.\n",
    "\n",
    "- A) Each individual turn is a document\n",
    "- B) The entire negotiation dialogue of both negotiators is a document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your answer]\n",
    "A) This ways doesn't allow to analyse the turns by their authors \n",
    "B) This is way to difficult to sparate and use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 (3 pt)**\n",
    "\n",
    "[A, 1 pt] Use the negotiation dataset to create a new dataframe called `df_document` with the following columns:\n",
    "- `negotiation_id`\n",
    "- `agent`\n",
    "- `document`\n",
    "\n",
    "Here, document is defined as described in question 1.1. That is: concatonate messages into a single string and split by the special character `\"\\n\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>message</th>\n",
       "      <th>negotiation_id</th>\n",
       "      <th>turn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>Hello! üôÇ Let's work together on a deal for the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>Hey! I'd like some more firewood to keep my do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>I need firewood as well. We have a large group...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>I see. üòÆ What are you least interested in?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>We can make do without extra water. Can we tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14266</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>Oh ok. I'm a little lazy when it comes to gath...</td>\n",
       "      <td>999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14267</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>So you get 3 firewood and 2 food? Are you sure?</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14268</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>If that's fine with you!</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14269</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>I think this deal is fair to both parties and ...</td>\n",
       "      <td>999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14270</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>Yeah, I tried to be as fair as possible</td>\n",
       "      <td>999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10277 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               agent                                            message  \\\n",
       "0      mturk_agent_1  Hello! üôÇ Let's work together on a deal for the...   \n",
       "1      mturk_agent_2  Hey! I'd like some more firewood to keep my do...   \n",
       "2      mturk_agent_1  I need firewood as well. We have a large group...   \n",
       "3      mturk_agent_2         I see. üòÆ What are you least interested in?   \n",
       "4      mturk_agent_1  We can make do without extra water. Can we tra...   \n",
       "...              ...                                                ...   \n",
       "14266  mturk_agent_1  Oh ok. I'm a little lazy when it comes to gath...   \n",
       "14267  mturk_agent_2    So you get 3 firewood and 2 food? Are you sure?   \n",
       "14268  mturk_agent_1                           If that's fine with you!   \n",
       "14269  mturk_agent_2  I think this deal is fair to both parties and ...   \n",
       "14270  mturk_agent_1            Yeah, I tried to be as fair as possible   \n",
       "\n",
       "       negotiation_id  turn  \n",
       "0                   0     0  \n",
       "1                   0     0  \n",
       "2                   0     1  \n",
       "3                   0     1  \n",
       "4                   0     2  \n",
       "...               ...   ...  \n",
       "14266             999     2  \n",
       "14267             999     3  \n",
       "14268             999     3  \n",
       "14269             999     4  \n",
       "14270             999     4  \n",
       "\n",
       "[10277 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document = df_negotiations[['negotiation_id','agent']]\n",
    "\n",
    "df_neg = df_negotiations.groupby(by=['agent', 'negotiation_id'])\n",
    "\n",
    "df_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_document['document'] = \"\\n\".join(df_neg['message']) ## Try to join by negotiation id to get all the turn from one negotition as one document\n",
    "df_document.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[B, 2pt] Next, merge this new dataframe with the `df_meta` dataframe. Print the the size and first five rows of the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14273, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>negotiation_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>Hello! üôÇ Let's work together on a deal for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>Hello! üôÇ Let's work together on a deal for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>Hello! üôÇ Let's work together on a deal for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>Hello! üôÇ Let's work together on a deal for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>Hello! üôÇ Let's work together on a deal for the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agent  age  gender  negotiation_id  outcome  \\\n",
       "0  mturk_agent_1   31  female             797       21   \n",
       "1  mturk_agent_1   31  female             797       21   \n",
       "2  mturk_agent_1   31  female             797       21   \n",
       "3  mturk_agent_1   31  female             797       21   \n",
       "4  mturk_agent_1   31  female             797       21   \n",
       "\n",
       "                                            document  \n",
       "0  Hello! üôÇ Let's work together on a deal for the...  \n",
       "1  Hello! üôÇ Let's work together on a deal for the...  \n",
       "2  Hello! üôÇ Let's work together on a deal for the...  \n",
       "3  Hello! üôÇ Let's work together on a deal for the...  \n",
       "4  Hello! üôÇ Let's work together on a deal for the...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_meta.merge(df_document,on=['negotiation_id', 'agent'])\n",
    "print(df_final.shape)\n",
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 (7 pt)**\n",
    "We would like to analyze the difference between \"best\" and \"worst\" performers based on `outcome`, top and bottom 10% respectively.\n",
    "\n",
    "[A, 2 pt] Find the top and bottom 10% thresholds for the `outcome` columns and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 percent :  0       21\n",
      "1       21\n",
      "2       21\n",
      "3       21\n",
      "4       21\n",
      "        ..\n",
      "1422    23\n",
      "1423    23\n",
      "1424    23\n",
      "1425    23\n",
      "1426    23\n",
      "Name: outcome, Length: 1427, dtype: int64\n",
      "bottom 10 percent :  0        21\n",
      "1        21\n",
      "2        21\n",
      "3        21\n",
      "4        21\n",
      "         ..\n",
      "12841    20\n",
      "12842    20\n",
      "12843    20\n",
      "12844    20\n",
      "12845    20\n",
      "Name: outcome, Length: 12846, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "percent_10 = round(0.1*df_final.shape[0])\n",
    "\n",
    "top_10 = df_final['outcome'][:percent_10]\n",
    "print(\"top 10 percent : \", top_10)\n",
    "\n",
    "bottom_10 = df_final['outcome'][:-percent_10]\n",
    "print(\"bottom 10 percent : \", bottom_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[B, 1pt] Create a TF-IDF matrix using the `TfidfVectorizer` form `sklearn`, setting `max_features=100` and `stop_words=\"english\"`. Print the resulting TF-IDF matrix shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      3\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_final\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocument\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(tfidf\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\ada_exam_2024\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2139\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2134\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2135\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2136\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2137\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2138\u001b[0m )\n\u001b[1;32m-> 2139\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\ada_exam_2024\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\ada_exam_2024\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1381\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1386\u001b[0m             )\n\u001b[0;32m   1387\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1392\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\ada_exam_2024\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1275\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1277\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1278\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\ada_exam_2024\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:115\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         doc \u001b[38;5;241m=\u001b[39m ngrams(doc)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\ada_exam_2024\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:244\u001b[0m, in \u001b[0;36m_VectorizerMixin._word_ngrams\u001b[1;34m(self, tokens, stop_words)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    239\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m         )\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_word_ngrams\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    245\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Turn tokens into a sequence of n-grams after stop words filtering\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;66;03m# handle stop words\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100, stop_words=\"english\", input='content')\n",
    "tfidf = vectorizer.fit_transform(df_final['document'])\n",
    "print(tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[C, 4pt] Use your thresholds and the TF-IDF matrix to print the top 10 terms for each type of negotiatior (i.e., the best and worst performing negotiators from question 1.3.A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 (8 pt)**\n",
    "You never get a second chance at a first impression! Let's investigate if the same goes for negotiations...\n",
    "\n",
    "[A, 1pt] Create a new df_document that only takes into account the first three (3) turns of each negotiator in a negotiation. Again, merge on the df_meta dataframe and print the resulting size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negotiation_id</th>\n",
       "      <th>agent</th>\n",
       "      <th>level_2</th>\n",
       "      <th>message</th>\n",
       "      <th>turn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello! üôÇ Let's work together on a deal for the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>2</td>\n",
       "      <td>I need firewood as well. We have a large group...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>4</td>\n",
       "      <td>We can make do without extra water. Can we tra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey! I'd like some more firewood to keep my do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>3</td>\n",
       "      <td>I see. üòÆ What are you least interested in?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>5</td>\n",
       "      <td>We could do without the water as well. I'm wil...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>14</td>\n",
       "      <td>I am good. I am pretty excited for the trip th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>16</td>\n",
       "      <td>Yes, Hopefully the weather holds up. So I was ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>18</td>\n",
       "      <td>Ok, I am willing to give you one food, in exch...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>13</td>\n",
       "      <td>Hello. How are you?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   negotiation_id          agent  level_2  \\\n",
       "0               0  mturk_agent_1        0   \n",
       "1               0  mturk_agent_1        2   \n",
       "2               0  mturk_agent_1        4   \n",
       "3               0  mturk_agent_2        1   \n",
       "4               0  mturk_agent_2        3   \n",
       "5               0  mturk_agent_2        5   \n",
       "6               1  mturk_agent_1       14   \n",
       "7               1  mturk_agent_1       16   \n",
       "8               1  mturk_agent_1       18   \n",
       "9               1  mturk_agent_2       13   \n",
       "\n",
       "                                             message  turn  \n",
       "0  Hello! üôÇ Let's work together on a deal for the...     0  \n",
       "1  I need firewood as well. We have a large group...     1  \n",
       "2  We can make do without extra water. Can we tra...     2  \n",
       "3  Hey! I'd like some more firewood to keep my do...     0  \n",
       "4         I see. üòÆ What are you least interested in?     1  \n",
       "5  We could do without the water as well. I'm wil...     2  \n",
       "6  I am good. I am pretty excited for the trip th...     0  \n",
       "7  Yes, Hopefully the weather holds up. So I was ...     1  \n",
       "8  Ok, I am willing to give you one food, in exch...     2  \n",
       "9                                Hello. How are you?     0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document2 = df_negotiations.groupby(['negotiation_id', 'agent']).apply(lambda x : x.head(3))[['message','turn']].reset_index()\n",
    "df_document2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>negotiation_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>level_2</th>\n",
       "      <th>message</th>\n",
       "      <th>turn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>11109</td>\n",
       "      <td>Hello. I am also hoping to get extra supplies....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>11111</td>\n",
       "      <td>I think that is fair but then I will need 1 wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>11113</td>\n",
       "      <td>Now lets talk about the extra firewood. Becaus...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>797</td>\n",
       "      <td>15</td>\n",
       "      <td>11108</td>\n",
       "      <td>Hello there! I am looking for extra supplies!üôÇ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>797</td>\n",
       "      <td>15</td>\n",
       "      <td>11110</td>\n",
       "      <td>I need food too unfortunately. So, how about I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agent  age  gender  negotiation_id  outcome  level_2  \\\n",
       "0  mturk_agent_1   31  female             797       21    11109   \n",
       "1  mturk_agent_1   31  female             797       21    11111   \n",
       "2  mturk_agent_1   31  female             797       21    11113   \n",
       "3  mturk_agent_2   26    male             797       15    11108   \n",
       "4  mturk_agent_2   26    male             797       15    11110   \n",
       "\n",
       "                                             message  turn  \n",
       "0  Hello. I am also hoping to get extra supplies....     0  \n",
       "1  I think that is fair but then I will need 1 wa...     1  \n",
       "2  Now lets talk about the extra firewood. Becaus...     2  \n",
       "3     Hello there! I am looking for extra supplies!üôÇ     0  \n",
       "4  I need food too unfortunately. So, how about I...     1  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final2 = df_meta.merge(df_document2,on=['negotiation_id', 'agent'])\n",
    "\n",
    "df_final2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[B, 1pt] Calculate the median negotiation outcome. Then, add a column called success to the df_document dataframe that is 1 if the outcome column is more than the median and 0 otherwise. Print the median outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median outcome 19.0\n"
     ]
    }
   ],
   "source": [
    "median_outcome = df_final2['outcome'].median()\n",
    "print(\"median outcome\", median_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>negotiation_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>level_2</th>\n",
       "      <th>message</th>\n",
       "      <th>turn</th>\n",
       "      <th>sucess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>11109</td>\n",
       "      <td>Hello. I am also hoping to get extra supplies....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>11111</td>\n",
       "      <td>I think that is fair but then I will need 1 wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mturk_agent_1</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>797</td>\n",
       "      <td>21</td>\n",
       "      <td>11113</td>\n",
       "      <td>Now lets talk about the extra firewood. Becaus...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>797</td>\n",
       "      <td>15</td>\n",
       "      <td>11108</td>\n",
       "      <td>Hello there! I am looking for extra supplies!üôÇ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mturk_agent_2</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>797</td>\n",
       "      <td>15</td>\n",
       "      <td>11110</td>\n",
       "      <td>I need food too unfortunately. So, how about I...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agent  age  gender  negotiation_id  outcome  level_2  \\\n",
       "0  mturk_agent_1   31  female             797       21    11109   \n",
       "1  mturk_agent_1   31  female             797       21    11111   \n",
       "2  mturk_agent_1   31  female             797       21    11113   \n",
       "3  mturk_agent_2   26    male             797       15    11108   \n",
       "4  mturk_agent_2   26    male             797       15    11110   \n",
       "\n",
       "                                             message  turn  sucess  \n",
       "0  Hello. I am also hoping to get extra supplies....     0       1  \n",
       "1  I think that is fair but then I will need 1 wa...     1       1  \n",
       "2  Now lets talk about the extra firewood. Becaus...     2       1  \n",
       "3     Hello there! I am looking for extra supplies!üôÇ     0       0  \n",
       "4  I need food too unfortunately. So, how about I...     1       0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final2['sucess'] = df_final2['outcome'].apply(lambda x : 1 if x>median_outcome else 0)\n",
    "df_final2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[C, 2pt] Create a TF-IDF matrix called `X` based on `df_document` using the following settings:\n",
    "\n",
    "`max_features=100, stop_words=\"english, ngram_range=(1, 2)`\n",
    "\n",
    "Additionally, create a variable `y` that corresponds to the success column. Finally, use `sklearn.model_selection.train_test_split` to split your data into a train and test set using parameters `test_size=0.2` and `random_state=99`.\n",
    "\n",
    "Print the shape of the TF-IDF and the shape of your train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (6168, 100)\n",
      "X_train shape  (4934, 100)\n",
      "X_test shape  (1234, 100)\n",
      "y_train shape  (4934,)\n",
      "y_test shape  (1234,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=100, stop_words=\"english\", ngram_range=(1,2))\n",
    "X =  vectorizer.fit_transform(df_final2['message'])\n",
    "print(\"X shape:\",X.shape)\n",
    "\n",
    "y = df_final2['sucess']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)\n",
    "\n",
    "print(\"X_train shape \", X_train.shape)\n",
    "print(\"X_test shape \", X_test.shape)\n",
    "print(\"y_train shape \", y_train.shape)\n",
    "print(\"y_test shape \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[D, 2pt] Use your prepared data to train a logistic regression model (`sklearn.linear_model.LogisticRegression`). Then, with the trained model predict on the test set and print a classification report (`sklearn.metrics.classification_report`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.97      0.77       785\n",
      "           1       0.31      0.02      0.04       449\n",
      "\n",
      "    accuracy                           0.63      1234\n",
      "   macro avg       0.47      0.50      0.40      1234\n",
      "weighted avg       0.52      0.63      0.50      1234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[E, 2pt] Use the weights of your trained model to show which terms mostly strongly correlate with high and low outcomes. Print the best five terms for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5 (9 pt)**\n",
    "You are concerned about potential ‚Äúconfounding‚Äù factors for your results in the previous question. Specifically, you would like to investigate the effect of ‚Äúgender‚Äù on the outcomes.\n",
    "\n",
    "[A, 3pt] Visualize the outcomes stratified by gender using a bar plot with standard deviation around the mean. Make sure you use clear x- and y-axis labels, a title, and a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[B, 2pt] Perform a T-Test with a confidence interval of 0.95 to check if the outcomes based on gender are statistically significantly different. Print the resulting t-statistic, the p-value, and your interpretation of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[C, 2pt] Finally, we would like to test if the gender distribution between high and low negotiation performers is significantly different. Please perform a chi-square test on the gender distribution of those negotiators scoring above the median outcome. Use a confidence interval of 0.95 and print the resulting chi-square statistic, p-value, and your interpretation of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[D, 2pt] /Discuss:/ In addition to the gender attribute, could you think of other measurable factors in this dataset that could be tested as confounders? List at least two more and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Insight Questions (15 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 (3pt)**\n",
    "In the context of analyzing negotiation turns, why would TF-IDF be more suitable than simple word frequency counts when trying to identify distinctive communication patterns between successful and unsuccessful negotiations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because TF-IDF adjusts word importance by considering both the frequency of a term within a document and its rarity across the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 (2pt)**\n",
    "How would you modify the standard TF-IDF implementation to account for the temporal nature of negotiation turns? Consider that early turns might be more important for setting the tone of the negotiation than later turns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would weight the turns and pass those weight to the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 (3 pt)**\n",
    "In our negotiation dataset, successful negotiators might simply write longer messages. How could this create a misleading interpretation of our TF-IDF results, and what would be a simple way to test for this potential bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could create a bias as the TF-IDF will consider that someone talking longer is more important. We could test this bias using a regression regarding the length of a message and checking for how much it count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 (3pt)**\n",
    "In our negotiation dataset, consider these two opening messages from different agents:\n",
    "\n",
    "Agent A: \"I propose we split the resources fairly\" Agent B: \"I suggest we divide the assets equitably\"\n",
    "\n",
    "These messages are semantically very similar but use different vocabulary. Explain:\n",
    "\n",
    "- a) How TF-IDF would process these messages differently\n",
    "- b) How word embeddings (like Word2Vec) would handle them\n",
    "- c) Why this distinction matters for negotiation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a)\n",
    "- b)\n",
    "- c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 (4pt)**\n",
    "Staying in the context of negotiations, explain why N-gram models such as bigrams might be more informative than unigrams for predicting negotiation outcomes. Provide two examples of bigrams that would be particularly meaningful in negotiation contexts but would lose their significance if split into unigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Analysis of Co-Author Network (50 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this part, you will analyze a reserach publication dataset derived from \n",
    "[social influence analysis in large-scale networks](https://keg.cs.tsinghua.edu.cn/jietang/publications/KDD09-Tang-et-al-Social-Influence-Analysis.pdf) (the paper itself is irrelevant to this exam, don't waste time reading it).\n",
    "\n",
    "The citation data is extracted from DBLP, ACM, MAG (Microsoft Academic Graph), and other sources. Each paper is associated with abstract, authors, year, venue, and title.\n",
    "\n",
    "Dataset: [citation dataset](https://cn.aminer.org/citation)\n",
    "\n",
    "Paper: [social influence analysis in large-scale networks](https://keg.cs.tsinghua.edu.cn/jietang/publications/KDD09-Tang-et-al-Social-Influence-Analysis.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from the web\n",
    "\n",
    "#### For Linux and MacOS:\n",
    "```bash\n",
    "wget https://lfs.aminer.cn/lab-datasets/citation/citation-network1.zip\n",
    "unzip citation-network1.zip\n",
    "ls -l outputacm.txt\n",
    "```\n",
    "\n",
    "#### For windows we recommend using WSL (Windows Subsystem for Linux) with above commands or directly downloading the file from the browser at \n",
    "https://lfs.aminer.cn/lab-datasets/citation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhelper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_data_as_df\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Define the file path\u001b[39;00m\n\u001b[0;32m     11\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputacm.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helper'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper import load_data_as_df\n",
    "\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"outputacm.txt\"\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = load_data_as_df(file_path)\n",
    "\n",
    "# check if the index column is the same as the index \n",
    "\n",
    "print(f\"Dataset loaded with {len(df)} entries.\")\n",
    "print(f\"colums: {df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 (6 pts)**: Analyze Papers Published Per Year\n",
    "\n",
    "**Objective:**  \n",
    "Analyze and visualize publication trends to understand how the research field has evolved over time.\n",
    "\n",
    "#### Instructions:\n",
    "1. Group the data by the year of publication and count the number of papers for each year (2 pts).\n",
    "2. Plot a bar chart showing the number of papers published per year from **1990 to 2010**. (2 pts)\n",
    "3. Focus on the pattern between **1996 and 2004**:\n",
    "   - **Discuss:** Describe any notable trends or changes in the number of publications during this period. (2 pts)\n",
    "   - **Bonus:** Hypothesize potential reasons for the observed pattern.  (2 pts)\n",
    "     *Hint: Consider events or trends related to the dataset's focus on computer science.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 (4 pts)**: Authors Per Paper Analysis\n",
    "\n",
    "With the rise of interdisciplinary research, multi-authored papers are becoming more common. This task will help us understand collaboration dynamics in the academic world.\n",
    "\n",
    "#### Instructions:\n",
    "- Get the number of authors for each paper and calculate the percentage of papers with four or more authors. (2 pts)\n",
    "- Plot a histogram to show the frequency distribution of the number of authors per paper (2 pts)(choose `bins=range(0, 30)` and set y-axis to log scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 (4 pts)**: Temporal Collaboration Trends\n",
    "\n",
    "Collaboration dynamics can change over time. This task will help us understand how collaboration trends have evolved in the academic world.\n",
    "\n",
    "#### Instructions:\n",
    "- Group the data by publication year, calculate the average number of authors per paper for each year, and create a line plot to visualize how it has changed from 1990 to 2010 (1 pt).\n",
    "- **Discuss:** There has been a hypothesis that the number of authors per paper has increased over time. Based on the plot, do you agree with this hypothesis ? (1 pt)\n",
    "- Compute the P-value of the hypothesis that the average number of authors per paper after 2000 is significantly higher than before 2000. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4 (6 pts)**: Build a Co-Author Network\n",
    "\n",
    "Co-author networks help us visualize and quantify collaborations in academia. Such networks are critical for identifying influential researchers and their role in fostering connections within their communities. Construct a network where nodes represent authors and edges represent collaborations.\n",
    "\n",
    "#### Instructions:\n",
    "- Create a graph where: (5 pts)\n",
    "  - Nodes: Each node represents a unique author, identified by their name in the authors field of the dataset.\n",
    "  - Edges: There is an edge between two nodes if the corresponding authors have co-authored at least one paper. The weight of the edge represents the number of papers the two authors have co-authored together.\n",
    "- After constructing the network, print the following information: (1 pt)\n",
    "  - The total number of nodes (authors) in the network.\n",
    "  - The total number of edges (collaborations) in the network.\n",
    "\n",
    "Example:\n",
    "\n",
    "For a paper authored by [\"Alice\", \"Bob\", \"Charlie\"], the graph should include:\n",
    "- Nodes: Alice, Bob, Charlie.\n",
    "- Edges: Alice-Bob, Alice-Charlie, Bob-Charlie, each with a weight of 1 (assuming no other collaborations between these pairs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5 (4 pts)**: Analyze the Co-Author Network\n",
    "\n",
    "Connected components in a co-author network can reveal isolated research communities or dominant research hubs. Analyzing the largest component helps us understand the core of academic collaboration\n",
    "\n",
    "#### Instructions:\n",
    "- The degree of a node is the number of edges connected to it. In the context of the co-author network, this represents the number of distinct co-authors an author has collaborated with. Compute the average degree of the network (1 pt).\n",
    "- Connectivity of the Network:\n",
    "  - A network is fully connected if there is a path between every pair of nodes. Determine if the co-author network is fully connected (2 pt). (Hint: A single answer is not enough here. You need to use a method to verify the connectivity of the network.)\n",
    "  - Can you tell how many authors are part of the largest connected component? How much does this account for the total number of authors in the network? (2 pt)\n",
    "<!-- - Compute the average clustering coefficient of the network. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.6 (4 pts)**: Top Authors by Collaborations\n",
    "\n",
    "#### Instructions:\n",
    "- Get the degree for all nodes in the network and print the top 10 authors by degree (1 pt) (Note: some entries (e.g., \"II,\" \"III,\" \"Jr.\") may not represent real authors due to data quality issues. Please keep them in the list and don't do any cleaning.)\n",
    "- A high degree  indicates that an author has collaborated with many other authors. However, it does not consider if the collaborations happen multiple times between the same authors. A weighted degree would be a better measure to consider the number of collaborations between authors. Get the top 10 authors by weighted degree. P.S. The weighted degree is the sum of the weights of the edges connected to the node. (1 pt)\n",
    "- Which two authors have the highest number of collaborations? How many papers have they co-authored together? (2 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.7 (4 pts)**: Analyze the reference/citation information \n",
    "\n",
    "Understanding the citation patterns of papers helps reveal their academic impact and how knowledge propagates through the research community. In this task, you will analyze the reference and citation relationships within the dataset.\n",
    "\n",
    "First, let's create a citation network where:\n",
    "- Nodes: Each node represents a unique paper, identified by its id in the dataset.\n",
    "- Edges: There is an edge from paper A to paper B if paper A cites paper B. \n",
    "\n",
    "\n",
    "#### Instructions:\n",
    "- **Discuss:** Is it reasonable that the citation network contains cycles?  What would a cycle( not self loop) in the citation network represent? (2 pt)\n",
    "- Which paper has the highest number of citations? How many papers cite this paper? (1 pt)\n",
    "- Which paper has the highest number of references? How many papers does this paper cite? (1 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.8 (3 pts)**: Analyze the Citation Distribution \n",
    "\n",
    "The citation distribution of papers can provide insights into the impact of research publications. In this task, you will analyze the citation distribution in the dataset.\n",
    "\n",
    "<!-- - Plot the number of papers having a certain level of citation x (x-axis) against x (y-axis) in a log-log scale. -->\n",
    "- Create a frequency distribution where the x-axis represents the number of citations and the y-axis represents the number of papers that have that number of citations. Plot two scatters plot of the frequency distribution first in a normal scale and second in a log-log scale. (2 pts)\n",
    "- **Discuss**: What does the plot suggest about the citation distribution in the dataset? (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.9 (3 pts)**: Central Tendency of Citation Distribution\n",
    "\n",
    "**Discuss:**: There are different ways to describe the central tendency of a citation distribution., such as mean. Determine the measure you think best represents the dataset and explain your reasoning. (Hint: Consider the distribution of the citation data above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.10 (2pts)**: Network Centrality Measures\n",
    "\n",
    "PageRank is a measure of influence based on link structure. Applying it to citations allows us to rank papers by their academic importance\n",
    "\n",
    "#### Instructions:\n",
    "- You are tasked with curating the 'Top 10 Influential Papers' from this dataset. Use PageRank to justify your selection and display the top 10 papers titles by page rank. (2 pts)\n",
    "- **bonus**: Identify patterns among the top-ranked papers. (2 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.11 (5 pts)**: Bridge Papers\n",
    "\n",
    "Bridge papers are those that connect different research communities. They are essential for fostering interdisciplinary research and knowledge transfer. \n",
    "\n",
    "#### Instructions: \n",
    "- Build a small citation network that only includes papers published in 2005. (2 pts)\n",
    "- Which measurement can help us identify bridge papers in a citation network?  (2 pt)\n",
    "- Try to find top10 bridge papers in the dataset. By looking at their titles, can you identify the research communities they connect? (Pick 2 papers) (1 pt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.12 (5 pts)**: Author-Citation Network\n",
    "\n",
    "In the previous tasks, we analyzed the co-author network and paper-citation network. In this task, we will analyze the author-citation network, where:\n",
    "- Nodes: Each node represents a unique author, identified by their name in the authors field of the dataset.\n",
    "- Edges: There is an edge from author A to author B if author A cites a paper authored by author B. \n",
    "- The weight of the edge represents the total number of citations from author A to author B.\n",
    "\n",
    "#### Instructions:\n",
    "- Given that we have a Author-Paper Matrix $A$ where each row represents an paper and each column represents an author. The value in the matrix is 1 if the author has contributed to the paper, 0 otherwise. And we also have a Paper-Paper citation matrix $P$ (square matrix) where the value at coordinates (i, j) is 1 if paper j cites paper i, 0 otherwise.\n",
    "- How can you get a Author-Author citation matrix from the above two matrices by matrix multiplication? (You don't need to implement this, just give the formula) (2 pts)\n",
    "- Author A may have never cited author B, but author A might have cited a few papers which cited works by author B. This can be seen as a 2nd degree citation.  More formally, a 2nd degree citation matrix $C_2$ has at each cell (i, j) the number 2nd degree citations from author i to author j. How can you get a 2nd degree citation matrix from the Author-Paper Matrix $A$ and Paper-Paper citation matrix $P$? (You don't need to implement this, just give the formula) (2 pts)\n",
    "- Can you generalize this to nth degree citation matrix? (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada_exam_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
